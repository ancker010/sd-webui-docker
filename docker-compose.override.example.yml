version: "3.7"
services:
  webui:
    ## Uncomment to use latest commit image (may be broken)
    # image: ghcr.io/neggles/sd-webui-docker:latest
    environment:
      ## passing some extra args and env vars to the container
      CLI_ARGS: "--allow-code --enable-insecure-extension-access --api --opt-channelslast --opt-sdp-attention"
      ## or use this for xformers
      # CLI_ARGS: "--allow-code --enable-insecure-extension-access --api --opt-channelslast --xformers"
      ## set up CUDA garbage collection
      PYTORCH_CUDA_ALLOC_CONF: "garbage_collection_threshold:0.9,max_split_size_mb:512"
      ## other CUDA-related options. Enabling these may speed things up or break things, YMMV
      # ACCELERATE: "true"
      CUDA_MODULE_LOADING: "LAZY"
      SAFETENSORS_FAST_GPU: "1"
      NUMEXPR_MAX_THREADS: "16"
      # nVidia still sets these in NGC containers, so may as well
      TORCH_CUDNN_V8_API_ENABLED: "1"
      TORCH_ALLOW_TF32_CUBLAS_OVERRIDE: "1"
      USE_EXPERIMENTAL_CUDNN_V8_API: "1"
    ## may help if you're using Accelerate
    ipc: host
    ## Set which GPU/GPUs to attach to the container
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
              device_ids: [ "0" ]

